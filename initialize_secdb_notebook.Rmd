---
title: 'SECDB - Database Initialization Notebook'
author: "H. David Shea"
date: 2021-02-09
output:
    github_document: default
---

```{r setup, include = FALSE}
library(DBI)
library(RSQLite)
library(tidyverse)

base_dir <- here::here("")
db_file <- fs::path(base_dir, "SECDB")

if(dbCanConnect(RSQLite::SQLite(), db_file)) {
    secdb <- dbConnect(RSQLite::SQLite(), db_file)
}

knitr::opts_chunk$set(
    connection = "secdb", # automatically uses this connection in sql chunks 
    comment = "#>", 
    collapse = TRUE, 
    message = FALSE,
    fig.width = 8,
    fig.asp = ((1 + sqrt(5)) / 2) - 1, # the golden ratio - technically, the b proportion of a+b when a is 1
    out.width = "70%",
    fig.align = "center"
)
```

## Introduction

This notebook documents _**and**_ initializes the `SECDB` basic stock research database.  Only the definition and group constituent tables are initialized with the chunks processed in this database.  However, all tables are dropped and recreated when running the processing chunks.  The database is currently designed to store stock research data for the stocks in the Dow Jones Industrial Average (DJIA) and the S&P 500 Index (SP500).  Currently, the DJIA stocks are all completely contained within the SP500.  If that were to change in the future, some additional processing would be required.  This initialization procedure assumes that the initiation date (`start_date` in time dependent definition and group constituent tables) for all data in the SECDB database is _today_.

Sidebar:  This notebook will also serve to document/experiment with mixing multiple execution engines within a single R Markdown document.  Specifically, I will use the `bash`, `sql`, and `r` engines in various processing chunks within this notebook.  One of the drawbacks that I have seen so far with chunks using the `sql` engine, is that only single `SQL` statements can be executed within the chunk.  So, when many `SQL` statements are _logically_ required together - for instance when dropping or recreating the entire schema - I have included the `SQL` statements in a script file and process them via the `SQLite` command within a `bash` engine chunk.

## Recreate SECDB

The next two code chunks process `SQL` scripts through the `sqlite3 SECDB` command via the `bash` engine.

This chunk references `DROP_SECDB_SCHEMA.SQL` as input to drop all of the schema objects for `SECDB `.  Note that if the schema objects do not exist, you will see warning messages.  

```{bash drop_schema, echo = TRUE}
sqlite3 SECDB < DROP_SECDB_SCHEMA.SQL
```

This chunk references `CREATE_SECDB_SCHEMA.SQL` as input to create all of the schema objects for `SECDB `.

```{bash create_schema, echo = TRUE}
sqlite3 SECDB < CREATE_SECDB_SCHEMA.SQL
```

The next chunk - which is an `r` chunk - uses the `RSQLite` function `dbListTables` to verify that the tables have been created.

```{r list_tables}
dbListTables(secdb)
```

## Initialize base SECDB definition and group constituent tables

As mentioned, the SECDB database is currently designed to store stock research data for the stocks in the Dow Jones Industrial Average (DJIA) and the S&P 500 Index (SP500).  The DJIA and the SP500 are identified as _stock universes_ in SECDB.  The `universe` table contains static definitions for all of the individual universe.

The following chunks are the raw `sql` code to initialize the instances of the DJIA and SP500 data within the `universe` table.  Note that these `INSERT` statements use the auto-populate primary key functionality in `SQLite` to fill in the `uid` fields with the next available sequential unique values allowed within the table.

```{sql initialize_djia}
INSERT
INTO   universe( name, description )
VALUES ( 'DJIA', 'Dow Jones Industrial Average' );
```
```{sql initialize_sp500}
INSERT
INTO   universe( name, description )
VALUES ( 'SP500', 'S&P 500 Index' );
```

And then, we can quickly check with the following raw `sql` chunk that the appropriate values have been inserted.

```{sql validate_universes, tab.cap = NA}
SELECT *
FROM   universe;
```

The other base data that we will populate within this notebook are populated with data sourced from wikipedia.  The `stock_data_access.R` script within this project collects the various data required by scraping various web pages.  These data include descriptive data for the securities in the DJIA and SP500, industry classification data for the securities, and the universe groupings for the DJIA and SP500 constituents.

The script is sourced below so that the tibbles produced are available for loading into the appropriate base tables.

```{r stock_data_script}
source(fs::path(base_dir, "stock_data_access.R"))
```

The data in the gics table are Global Industry Classification Standard (GICSÂ®) data developed by MSCI and Standard & Poor's in 1999.  They establish a hierarchy of sector, industry group, industry and sub-industry classifications for a broad array of global stocks.

For the GICS data, the tibbles `sct_tbl`, `igp_tbl`, `ind_tbl` and `sub_tbl` contain data for GICS sectors, industry groups, industries and sub-industries, respectively.  They all have the same column structure.  The following `r` chunk uses the base `DBI` function `dbAppendTable` to `INSERT` the data from the four tibbles.

```{r load_gics_data}
dbAppendTable(secdb, "gics", sct_tbl)

dbAppendTable(secdb, "gics", igp_tbl)

dbAppendTable(secdb, "gics", ind_tbl)

dbAppendTable(secdb, "gics", sub_tbl)
```

Note that the `dbAppendTable` calls return the number of rows inserted into the table for each call.  And, we can check with the following raw `sql` chunks to verify that the data are loaded correctly. 

```{sql sct_select}
SELECT *
FROM   gics
WHERE  level = 'SCT';
```
```{sql igp_select}
SELECT * 
FROM   gics
WHERE  level = 'IGP';
```
```{sql ind_select}
SELECT * 
FROM   gics
WHERE  level = 'IND';
```
```{sql sub_select}
SELECT *
FROM   gics
WHERE  level = 'SUB';
```

Note that for `sql` chunks, the default in R Markdown is to display the first 10 records returned by `SELECT` statements in a document.  This can be changed with the chunk option `max.print` which can be set equal to a specific number ro to no limit by using `max.print = -1` or `max.print = NA`.

For descriptive security data, the above script pulled data for the S&P 500 index constituents and the Dow Jones Industrial Average constituents.  As mentioned in the introduction, all of the DJIA stocks are contained within the SP500 stocks.  As such, only the SP500 descriptive data will be used to initialize the `security` table.

For the SP500 data are contained in the tibble `SP500_tbl`.  For the initialization, the sourced file above assumed that the `security` table was empty and created `uid` values explicitly.  This is actually required because the auto-populate primary key functionality in `SQLite` only works when there is a single integer field primary key.  The primary key for the `security` table references the `uid` and the `start_date` fields.

The data in the `sp500_tbl` mimic the tables structure for the `security` table which is required in order to use the `dbAppendTable` function.

```{r review_sp500_tbl}
sp500_tbl
```

The following `r` chunk uses the base `DBI` function `dbAppendTable` to `INSERT` the data from the `sp500_tbl` tibble into the `security` table.

```{r load_security_data}
dbAppendTable(secdb, "security", sp500_tbl)
```

And, we can check with the following raw `sql` chunks to verify that the security data are loaded correctly. I also take the opportunity here to display a `SQL` join between the `security` table and the `gics` table to display the sector name for the security which is accessed by using the first two digits of the `sub_industry_code` for the security. Note that `SQL` does all of the appropriate number and character and back to number conversion that is required to make the `WHERE` clause join logic work correctly.

```{sql security_select}
SELECT uid,
       DATE(start_date) AS start_date,
       DATE(end_date) AS end_date,
       symbol,
       security.name AS name,
       gics.name AS sector
FROM   security,
       gics
WHERE  gics.level = 'SCT'
  AND  gics.code = SUBSTR(security.sub_industry_code,1,2);
```

The final pieces of data to initialize in the `SECDB` are the group constituent data for the DJIA and SP500 stocks.  These data are maintained in the `universe_constituent` table in the `SECDB`.

The following raw `sql` chunk displays a _poorly documented_ technique for investigating the makeup of a `SQLite` schema object.  Each `SQLite` database has a _hidden_ table named `sqlite_schema` which contains information about the makeup of the objects in the schema.  The `name` field identifies the object and the `sql` field shows the `SQL` statement that was executed to create the object.  (N.B., There are easier - maybe better - ways to accomplish what the next two chunks accomplish, but this is an opportunity to show the interplay functionality between the different processing chunks - even with different engines - within R Markdown.)

```{sql query_sqlite_schema, output.var = "sql_string"}
SELECT  sql
FROM    sqlite_schema
WHERE   name = 'universe_constituent';
```
```{r pretty_print_results, echo = FALSE, comment = ""}
cat(sql_string$sql)
```

Note that most of the data we need to initialize the `universe_constituent` table for both the DJIA and the SP500 are contained in the tibbles that we sourced previously - `djia_tbl` and `sp500_tbl`, respectively.  The missing data items are the `uid` value for each of the universes.

The following code chunks use raw `sql` to access the `universe` data (and make that data available via `universe_tbl`) and then `r` to join the `universe` data with the DJIA and SP500 data and appropraite load the `universe_constituent` table.

```{sql query_universe, output.var = "universe_tbl"}
SELECT  uid, name
FROM    universe
WHERE   name in ('DJIA', 'SP500');
```
```{r uc_data_prep}
universe_tbl <- tibble::tibble(universe_tbl)

sp500_uid <- universe_tbl %>% filter(name == 'SP500') %>% select(uid)
djia_uid <- universe_tbl %>% filter(name == 'DJIA') %>% select(uid)

sp500_const <- sp500_tbl %>%
  transmute(
    universe_uid = sp500_uid$uid,
    security_uid = uid,
    start_date = start_date,
    end_date = end_date
  )

djia_const <- djia_tbl %>%
  transmute(
    universe_uid = djia_uid$uid,
    security_uid = uid,
    start_date = start_date,
    end_date = end_date
  )

dbAppendTable(secdb, "universe_constituent", sp500_const)

dbAppendTable(secdb, "universe_constituent", djia_const)
```

And, we can check with the following raw `sql` chunks to verify that the universe constituent data are loaded correctly.

```{sql verify_sp500_const}
SELECT  S.uid AS uid,
        S.symbol AS symbol,
        S.name AS name,
        U.name AS universe
FROM    universe U,
        universe_constituent UC,
        security S
WHERE   U.name = 'SP500'
  AND   U.uid  = UC.universe_uid
  AND   UC.start_date <= DATE('now')
  AND   UC.end_date > DATE('now')
  AND   UC.security_uid = S.uid
  AND   S.start_date <= DATE('now')
  AND   S.end_date > DATE('now');
```

```{sql verify_djia_const}
SELECT  S.uid AS uid,
        S.symbol AS symbol,
        S.name AS name,
        U.name AS universe
FROM    universe U,
        universe_constituent UC,
        security S
WHERE   U.name = 'DJIA'
  AND   U.uid  = UC.universe_uid
  AND   UC.start_date <= DATE('now')
  AND   UC.end_date > DATE('now')
  AND   UC.security_uid = S.uid
  AND   S.start_date <= DATE('now')
  AND   S.end_date > DATE('now');
```
